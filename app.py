import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json

st.set_page_config(page_title="Website Outreach AI Agent", layout="wide")

# Load API key from Streamlit secrets
GROQ_API_KEY = st.secrets["GROQ_API_KEY"]

API_URL = "https://api.groq.com/openai/v1/chat/completions"
MODEL_NAME = "llama-3.3-70b-versatile"

# -------------------------
# Scrape Website Content
# -------------------------
def scrape_website(url):
    try:
        r = requests.get(url, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        text = soup.get_text(separator=" ", strip=True)
        return text[:4000]
    except Exception as e:
        st.warning(f"Failed to scrape {url}: {e}")
        return ""

# -------------------------
# Extract JSON Insights
# -------------------------
def extract_json(content):
    try:
        start = content.find("{")
        end = content.rfind("}") + 1
        json_str = content[start:end]
        return json.loads(json_str)
    except:
        return None

# -------------------------
# Groq AI API Call
# -------------------------
def groq_ai_analyze(url, text, style):
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }

    email_tone = (
        "Strong and professional with clear CTA to offer **targeted B2B email lists**."
        if style == "Professional"
        else "Friendly, humble tone with CTA offering a **sample targeted B2B email list**."
    )

    prompt = f"""
You are a B2B sales outreach AI Agent.
Analyze the company using the URL and scraped content below.

Your response MUST begin with ONLY the following JSON structure (no extra words):

{{
"company_summary": "2-3 line summary",
"main_products": ["service 1", "service 2", "service 3"],
"ideal_customers": ["ICP 1", "ICP 2", "ICP 3"],
"outreach_angles": ["angle 1", "angle 2", "angle 3"]
}}

After that JSON block, generate:

ğŸ“§ Subject Line:
ğŸ“ Email Body:
- {email_tone}
- 6â€“9 sentences
- Include emojis when helpful (subtle)

Website: {url}

Scraped Content:
{text}
"""

    body = {
        "model": MODEL_NAME,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.65
    }

    try:
        r = requests.post(API_URL, headers=headers, json=body)
        res = r.json()

        if "choices" not in res:
            return f"âŒ Unexpected Response: {json.dumps(res)}"

        return res["choices"][0]["message"]["content"]

    except Exception as e:
        return f"âš ï¸ API Error: {e}"

# -------------------------
# Extract Email Subject + Body
# -------------------------
def parse_email(content):
    subject = ""
    body = ""
    lines = content.splitlines()
    collect = False
    buff = []

    for line in lines:
        if "ğŸ“§" in line:
            subject = line.replace("ğŸ“§ Subject Line:", "").replace("ğŸ“§ Email Subject:", "").strip()
        if "ğŸ“" in line:
            collect = True
            continue
        if collect:
            buff.append(line)

    body = "\n".join(buff).strip()
    return subject, body

# -------------------------
# Single URL Mode
# -------------------------
def analyze_single_url():
    url = st.text_input("Enter Website URL:")
    
    if st.button("Analyze"):
        if url:
            scraped = scrape_website(url)

            st.subheader("â³ AI Processing... Please wait")

            # Both Styles
            prof = groq_ai_analyze(url, scraped, "Professional")
            conv = groq_ai_analyze(url, scraped, "Conversational")

            # Extract JSON insights from professional output
            insights_json = extract_json(prof)

            if insights_json:
                insights_display = (
                    f"ğŸ“Œ Company Summary:\n{insights_json['company_summary']}\n\n"
                    f"ğŸ·ï¸ Key Products:\n- " + "\n- ".join(insights_json['main_products']) + "\n\n"
                    f"ğŸ¯ Ideal Customers:\n- " + "\n- ".join(insights_json['ideal_customers']) + "\n\n"
                    f"ğŸ’¡ Outreach Angles:\n- " + "\n- ".join(insights_json['outreach_angles'])
                )
            else:
                insights_display = "âš ï¸ Insights unavailable â€” Try again"

            # Parse Emails
            sp, bp = parse_email(prof)
            sh, bh = parse_email(conv)

            st.subheader("ğŸ¢ Company Insights")
            st.text_area("Insights", insights_display, height=300)

            st.subheader("1ï¸âƒ£ Professional Email")
            st.text_area("Professional Email", f"ğŸ“§ {sp}\n\nğŸ“\n{bp}", height=650)

            st.subheader("2ï¸âƒ£ Conversational Email")
            st.text_area("Conversational Email", f"ğŸ“§ {sh}\n\nğŸ“\n{bh}", height=650)


# -------------------------
# Bulk CSV Mode (unchanged)
# -------------------------
def analyze_bulk():
    file = st.file_uploader("Upload CSV with 'url' column", type=["csv"])

    if file is not None:
        df = pd.read_csv(file)

        if "url" not in df.columns:
            st.error("CSV must contain a 'url' column")
            return

        if st.button("Run Bulk Analysis"):
            results = []
            progress = st.progress(0)

            for i, row in df.iterrows():
                url = row["url"]
                scraped = scrape_website(url)

                prof = groq_ai_analyze(url, scraped, "Professional")
                conv = groq_ai_analyze(url, scraped, "Conversational")

                sp, bp = parse_email(prof)
                sh, bh = parse_email(conv)

                results.append({
                    "url": url,
                    "professional_subject": sp,
                    "professional_body": bp,
                    "conversational_subject": sh,
                    "conversational_body": bh
                })

                progress.progress((i + 1) / len(df))

            result_df = pd.DataFrame(results)
            st.success("Bulk Analysis Completed!")
            st.dataframe(result_df)

            st.download_button(
                "Download Results CSV",
                result_df.to_csv(index=False).encode("utf-8"),
                "results.csv",
                "text/csv"
            )

# -------------------------
# Layout
# -------------------------
st.title("ğŸŒ Website Outreach AI Agent (Groq)")

mode = st.radio("Select Mode", ["Single URL", "Bulk CSV Upload"])

if mode == "Single URL":
    analyze_single_url()
else:
    analyze_bulk()
